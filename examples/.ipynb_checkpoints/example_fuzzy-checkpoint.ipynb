{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huff, Puff & Classify\n",
    "### Example Notebook: Fuzzy String Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "#import custom modules\n",
    "import prep.prep_data as prep\n",
    "import prep.prep_cv as cv\n",
    "import model.fuzzy as fz\n",
    "\n",
    "#magik\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Globals\n",
    "#TODO: Add instructions for user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup globals\n",
    "#setup directories\n",
    "CWD = os.getcwd()\n",
    "HOME_DIR = os.path.abspath(os.path.join(CWD, os.pardir))\n",
    "DATA_DIR = HOME_DIR + \"/data\"\n",
    "DATA_FILENAME = \"housing_data.csv\"\n",
    "RESULTS_DIR = HOME_DIR + \"/results\"\n",
    "\n",
    "#setup lists of vars to work with\n",
    "STR_VARS = ['housing_roof', 'housing_wall', 'housing_floor']\n",
    "NUM_VARS = [s + '_num' for s in STR_VARS]\n",
    "RANK_VARS = [s + '_rank' for s in STR_VARS]\n",
    "\n",
    "#which variable do you want to predictn (currently: floor/wall/roof)\n",
    "PRED_VAR = \"housing_roof\"\n",
    "PRED_VAR = PRED_VAR + \"_rank\" #will always be using the strings to predict ranking\n",
    "\n",
    "#setup a filter to select which surveys you want to work with\n",
    "SVY_FILTER = ['MACRO_DHS']\n",
    "\n",
    "#analytical options\n",
    "CV_SAMPLE_PCT = .2 #hold out x% for testing\n",
    "CV_SAMPLE_WT = \"N\" #which variable(if any) shall weight your test sample\n",
    "CV_FOLDS = 3 #use a x-fold cross-validation env\n",
    "\n",
    "#garbage lists\n",
    "STR_GARBAGE = ['nan', 'other', 'not a dejure resident', 'not dejure resident']\n",
    "RANK_GARBAGE = ['4', '5', '6', '7', '8', '9', 'n']\n",
    "\n",
    "#dictionaries\n",
    "PRED_DICT = {'natural':'1', 'rudimentary':'2', 'finished':'3'} #map categories back to ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in and prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in data and clean the text, then subset to our gold standard MACRO DHS data\n",
    "df = prep.read_then_clean(DATA_DIR + \"/\" + DATA_FILENAME, STR_VARS, SVY_FILTER)\n",
    "\n",
    "#remove garbage codes from our string variables\n",
    "df_clean = prep.remove_garbage_codes(df, STR_VARS, STR_GARBAGE)\n",
    "\n",
    "#extract ranking values for roof/wall/floor, then remove non-informative values\n",
    "#note that we only want to use ranks from 1-3, as these correspond to our final output ranks\n",
    "df_clean = prep.extract_ranking(df_clean, NUM_VARS)\n",
    "df_clean = prep.remove_garbage_codes(df_clean, RANK_VARS, RANK_GARBAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run a bifold cross validation exercise for \"housing roof\"\n",
    "##### Since this is an example, we will only work on 25 unknown words from each cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup training/test data for a bifold cross validation, using the 'housing roof\" variable to predict \n",
    "train_list = cv.cv_censor_col(df_clean, PRED_VAR, CV_SAMPLE_PCT, CV_SAMPLE_WT, CV_FOLDS)\n",
    "\n",
    "#run bifold cross validation for \"housing roof\"\n",
    "#run your cross-validation analysis\n",
    "cv_distrib, cv_preds, cv_results, cv_df = fuzzy_cv(train_list, PRED_VAR, PRED_DICT,\n",
    "                                                   subset=[0:25]) #only run on 25 words from each CV for speed\n",
    "\n",
    "#output the results to csv\n",
    "save_results_df(cv_results, out_dir, \"cv_results\")\n",
    "save_results_df(cv_preds, out_dir, \"cv_preds\")\n",
    "save_results_df(cv_df, out_dir, \"cv_df\")\n",
    "save_results_df(cv_distrib, out_dir, \"cv_distrib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot results\n",
    "fz.fuzzy_density(pd.concat(cv_distrib), 'word', \n",
    "                 ['natural', 'rudimentary', 'finished'],\n",
    "                 color_list={'natural':'r', 'rudimentary':'b', 'finished':'g'},\n",
    "                 cutoff=75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
