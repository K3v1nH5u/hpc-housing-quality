{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SANDBOX for code development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#import custom modules\n",
    "import prep.prep_data as prep\n",
    "import prep.prep_cv as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~begin reading\n",
      "data read!\n",
      "~begin cleaning\n",
      "data clean!\n",
      "~applying filter\n"
     ]
    }
   ],
   "source": [
    "df = prep.read_then_clean('../data/housing_data.csv',\n",
    "                          ['housing_roof', 'housing_wall', 'housing_floor'],\n",
    "                          ['MACRO_DHS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nan': 'impute', 'other': 'impute', 'not a dejure resident': 'impute', 'not dejure resident': 'impute'}\n",
      "removing garbage from  housing_roof\n",
      "removing garbage from  housing_wall\n",
      "removing garbage from  housing_floor\n"
     ]
    }
   ],
   "source": [
    "df_clean = remove_garbage_codes(df, \n",
    "                                ['housing_roof', 'housing_wall', 'housing_floor'],\n",
    "                                ['nan', 'other', 'not a dejure resident', 'not dejure resident'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nan': 'replace_me', 'other': 'replace_me', 'not a dejure resident': 'replace_me', 'not dejure resident': 'replace_me'}\n"
     ]
    }
   ],
   "source": [
    "df_clean = df\n",
    "\n",
    "# build dictionary to map all garbage values to NaN\n",
    "garb_dict = {}\n",
    "for string in ['nan', 'other', 'not a dejure resident', 'not dejure resident']:\n",
    "    garb_dict[string] = \"replace_me\"\n",
    "\n",
    "print(garb_dict)\n",
    "\n",
    "df_clean['housing_roof'] = df_clean['housing_roof'].map(garb_dict).fillna(df_clean['housing_roof'])\n",
    "df_clean['housing_roof'] = df_clean['housing_roof'].replace(\"replace_me\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_list = cv.cv_censor_col(df, 'housing_roof_num', .2, 'N', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ihme_loc_id</th>\n",
       "      <th>nid</th>\n",
       "      <th>survey_series</th>\n",
       "      <th>hhweight</th>\n",
       "      <th>urban</th>\n",
       "      <th>hh_size</th>\n",
       "      <th>int_year</th>\n",
       "      <th>housing_roof</th>\n",
       "      <th>housing_wall</th>\n",
       "      <th>housing_floor</th>\n",
       "      <th>housing_roof_num</th>\n",
       "      <th>housing_wall_num</th>\n",
       "      <th>housing_floor_num</th>\n",
       "      <th>iso3</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>index</th>\n",
       "      <th>region_id</th>\n",
       "      <th>super_region_id</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56099</td>\n",
       "      <td>MACRO_DHS</td>\n",
       "      <td>695752.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>None</td>\n",
       "      <td>cement bricks</td>\n",
       "      <td>carpet</td>\n",
       "      <td>99</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>AFG</td>\n",
       "      <td>28108</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56099</td>\n",
       "      <td>MACRO_DHS</td>\n",
       "      <td>695752.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>None</td>\n",
       "      <td>hay with mud</td>\n",
       "      <td>nan</td>\n",
       "      <td>96</td>\n",
       "      <td>21</td>\n",
       "      <td>96</td>\n",
       "      <td>AFG</td>\n",
       "      <td>28108</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56099</td>\n",
       "      <td>MACRO_DHS</td>\n",
       "      <td>1075029.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>None</td>\n",
       "      <td>hay with mud</td>\n",
       "      <td>mud and hay</td>\n",
       "      <td>96</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>AFG</td>\n",
       "      <td>28108</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>137</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56099</td>\n",
       "      <td>MACRO_DHS</td>\n",
       "      <td>897294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>None</td>\n",
       "      <td>no walls</td>\n",
       "      <td>earth sand</td>\n",
       "      <td>96</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>AFG</td>\n",
       "      <td>28108</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56099</td>\n",
       "      <td>MACRO_DHS</td>\n",
       "      <td>695752.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>None</td>\n",
       "      <td>no walls</td>\n",
       "      <td>vinyl or plastic strips</td>\n",
       "      <td>96</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>AFG</td>\n",
       "      <td>28108</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 ihme_loc_id    nid survey_series   hhweight  urban  hh_size  \\\n",
       "0           1         AFG  56099     MACRO_DHS   695752.0    0.0      1.0   \n",
       "1           2         AFG  56099     MACRO_DHS   695752.0    0.0      1.0   \n",
       "2           3         AFG  56099     MACRO_DHS  1075029.0    0.0      1.0   \n",
       "3           4         AFG  56099     MACRO_DHS   897294.0    0.0      1.0   \n",
       "4           5         AFG  56099     MACRO_DHS   695752.0    0.0      1.0   \n",
       "\n",
       "   int_year housing_roof   housing_wall            housing_floor  \\\n",
       "0      2010         None  cement bricks                   carpet   \n",
       "1      2010         None   hay with mud                      nan   \n",
       "2      2010         None   hay with mud              mud and hay   \n",
       "3      2010         None       no walls               earth sand   \n",
       "4      2010         None       no walls  vinyl or plastic strips   \n",
       "\n",
       "  housing_roof_num housing_wall_num housing_floor_num iso3  cluster_id  index  \\\n",
       "0               99               33                41  AFG       28108      1   \n",
       "1               96               21                96  AFG       28108      2   \n",
       "2               96               21                13  AFG       28108      3   \n",
       "3               96               11                11  AFG       28108      4   \n",
       "4               96               11                32  AFG       28108      5   \n",
       "\n",
       "   region_id  super_region_id    N  \n",
       "0        138              137  1.0  \n",
       "1        138              137  1.0  \n",
       "2        138              137  2.0  \n",
       "3        138              137  1.0  \n",
       "4        138              137  1.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(new_df['housing_roof_num'].isnull().sum() - new_df['housing_roof_num_og'].isnull().sum())/ len(new_df)\n",
    "#pd.crosstab(new_df['housing_roof'], columns='count', dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%file ./prep/prep_cv.py\n",
    "\n",
    "#define necessary helper functions\n",
    "def cv_censor_col(df, colname, pct, weight_var, reps):\n",
    "    \n",
    "    #import packages\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    for x in range(reps):\n",
    "            \n",
    "        print(\"sampling df, iteration #\", x)\n",
    "    \n",
    "        #first archive your old column in order to test later\n",
    "        new_df = df.copy()\n",
    "        new_df[colname + '_og'] = new_df[colname]\n",
    "\n",
    "        #draw a weighted sample\n",
    "        df_censor = new_df.sample(frac=pct, weights=weight_var)\n",
    "\n",
    "        #now replace the sampled column with missing values in order to try and predict\n",
    "        #note that replacement is only done on the sampled indices\n",
    "        df_censor[colname] = \"replace_me\"\n",
    "        new_df.update(df_censor, overwrite=True)\n",
    "        new_df[colname].replace(\"replace_me\", np.nan, inplace=True)\n",
    "        #TODO unsure if this is pythonic method but it seems like df.update won't replace values with NaN, \n",
    "        #as such, need to do this workaround\n",
    "        \n",
    "        #store the result (df with columns censored)\n",
    "        out.append(new_df)\n",
    "    \n",
    "    #return the list of sampled dfs\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#look at output datset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nan',\n",
       " 'cardboard cloth tent',\n",
       " 'cement bricks',\n",
       " 'ceramic tiles',\n",
       " 'metal',\n",
       " 'roofing shingles',\n",
       " 'rustic mat mud with hay',\n",
       " 'sod mud with grass',\n",
       " 'thatch bushes grass',\n",
       " 'wood planks',\n",
       " 'wood timber',\n",
       " 'no roof',\n",
       " 'calamine cement fiber',\n",
       " 'cement',\n",
       " 'mud and hay',\n",
       " 'other',\n",
       " 'rustic mat',\n",
       " 'wood',\n",
       " 'grass palm',\n",
       " 'zinc plates',\n",
       " 'concrete slab',\n",
       " 'palm bamboo',\n",
       " 'cardboard',\n",
       " 'tiles',\n",
       " 'reinforced concrete',\n",
       " 'tuale tarred roofing paper',\n",
       " 'thatch palm leaf',\n",
       " 'concrete panels',\n",
       " 'ruberoid asbest',\n",
       " 'slate',\n",
       " 'tol kir',\n",
       " 'adobe',\n",
       " 'metallique',\n",
       " 'tuiles',\n",
       " 'vegetal',\n",
       " 'autre',\n",
       " 'eternit',\n",
       " 'local tiling',\n",
       " 'zinc cement fiber',\n",
       " 'tiles slate',\n",
       " 'sod',\n",
       " 'shingles',\n",
       " 'earth',\n",
       " 'straw',\n",
       " 'tole',\n",
       " 'tuile',\n",
       " 'tile tole',\n",
       " 'leaves',\n",
       " 'tile tuile',\n",
       " 'palm branches',\n",
       " 'tile',\n",
       " 'stone slabs',\n",
       " 'palms bamboo',\n",
       " 'finished roof',\n",
       " 'natural roof',\n",
       " 'rudimentary roof',\n",
       " 'cement concrete',\n",
       " 'jute bamboo mud',\n",
       " 'tin',\n",
       " 'katcha bamboo thatch',\n",
       " 'cement concrete tiled',\n",
       " 'bamboo',\n",
       " 'earth bamboo',\n",
       " 'concrete',\n",
       " 'corrugated iron',\n",
       " 'roof tiles',\n",
       " 'straw cane palms',\n",
       " 'calamine',\n",
       " 'concret',\n",
       " 'palm tree',\n",
       " 'calamina plancha',\n",
       " 'losade hormigon armado',\n",
       " 'tiles teja',\n",
       " 'cane palm mud',\n",
       " 'clay tiles',\n",
       " 'eternit amianto',\n",
       " 'polished wood',\n",
       " 'raw wood',\n",
       " 'zinc',\n",
       " 'palm straw',\n",
       " 'planches en bois',\n",
       " 'tle',\n",
       " 'tuiles ardoise eternit',\n",
       " 'chaume palme feuilles',\n",
       " 'dalles en bton',\n",
       " 'natte',\n",
       " 'palme bambou',\n",
       " 'lump of earth',\n",
       " 'paille chaume natte',\n",
       " 'yagua',\n",
       " 'asbest cement',\n",
       " 'carton zinc',\n",
       " 'asbest tiles',\n",
       " 'cardboard zinc',\n",
       " 'bamboo cane',\n",
       " 'asbestos',\n",
       " 'palm leaves cana',\n",
       " 'palm tree yagua',\n",
       " 'tiles tejas',\n",
       " 'plywood',\n",
       " 'asbesto',\n",
       " 'cana',\n",
       " 'palm leave',\n",
       " 'thatch leaf',\n",
       " 'reed bamboo',\n",
       " 'rustic mat plastic sheets',\n",
       " 'thatch',\n",
       " 'wood or mulch',\n",
       " 'reed or bamboo',\n",
       " 'plastic sheet',\n",
       " 'cement or concrete',\n",
       " 'corrugated iron metal',\n",
       " 'thatch leaf mud',\n",
       " 'asbestos cement fiber',\n",
       " 'metal corrugated iron',\n",
       " 'thatch mud',\n",
       " 'corrugated iron sheet ceiling',\n",
       " 'corrugated iron sheet only',\n",
       " 'plastic carton used metal sheet',\n",
       " 'straw branch palm leaf',\n",
       " 'tiles slates',\n",
       " 'metal and ceiling',\n",
       " 'metal only',\n",
       " 'plastic cardboard',\n",
       " 'bark straw palm bamboo',\n",
       " 'aluminum iron sheets',\n",
       " 'thatch grass',\n",
       " 'asbestos slate roofing sheets',\n",
       " 'ceramic tiles brick tiles',\n",
       " 'finished asbestos slate roofing sheets',\n",
       " 'finished cement',\n",
       " 'finished zinc aluminium',\n",
       " 'rudimentary cardboard',\n",
       " 'finished ceramic brick tiles',\n",
       " 'finished roofing shingles',\n",
       " 'rudimentary palm bamboo',\n",
       " 'rudimentary rustic mat',\n",
       " 'finished wood',\n",
       " 'natural thatch palm leaf',\n",
       " 'natural mud sod',\n",
       " 'finished calamine cement fiber',\n",
       " 'rudimentary wood planks',\n",
       " 'slab',\n",
       " 'tile mud ceramic concrete',\n",
       " 'wood panel',\n",
       " 'cement fiber',\n",
       " 'straw palm',\n",
       " 'no walls',\n",
       " 'cement tiles',\n",
       " 'mud tiles',\n",
       " 'no roofing',\n",
       " 'thach palm leaf',\n",
       " 'waste material',\n",
       " 'canvas tent',\n",
       " 'asbestos zinc',\n",
       " 'brick concrete',\n",
       " 'metal tiles',\n",
       " 'metal zinc',\n",
       " 'thatch palm leaf sod',\n",
       " 'wood sirap',\n",
       " 'asbestos sheets',\n",
       " 'burnt brick',\n",
       " 'loosely packed stone',\n",
       " 'metal gi',\n",
       " 'mud',\n",
       " 'plastic polythene sheeting',\n",
       " 'raw wood planks timber',\n",
       " 'rcc rbc cement concrete',\n",
       " 'sod mud and grass mixture',\n",
       " 'unburnt bricks',\n",
       " 'asbestos wood zinc',\n",
       " 'mud bricks',\n",
       " 'mud bricks with stones',\n",
       " 'hair wool cloth',\n",
       " 'grass thatch',\n",
       " 'corrugated iron mabati',\n",
       " 'grass thatch makuti',\n",
       " 'tin cans',\n",
       " 'corregated iron mabati',\n",
       " 'dung mud',\n",
       " 'asbestos sheet',\n",
       " 'iron sheets',\n",
       " 'thatch grass makuti',\n",
       " 'dung mud sod',\n",
       " 'cement beton blocks',\n",
       " 'tar',\n",
       " 'galvanized iron aluminium',\n",
       " 'thatch palm bamboo bark',\n",
       " 'tiles cement concrete fibrous',\n",
       " 'plastic sheet tent',\n",
       " 'palm bamboo thatch',\n",
       " 'bamboo thatch palm leaf',\n",
       " 'zinc metal',\n",
       " 'asphalt asbestos',\n",
       " 'tarpaulin plastic',\n",
       " 'asbestos sheets shingles',\n",
       " 'concrete cement',\n",
       " 'palm bamboo mats',\n",
       " 'zinc metal aluminum',\n",
       " 'cadjan palmayra strw',\n",
       " 'waste materials',\n",
       " 'finished roofing metal',\n",
       " 'natural roofing thatch grass',\n",
       " 'roofing tiles',\n",
       " 'rudimentary roofing wood planks',\n",
       " 'ceramic clay tiles',\n",
       " 'metal corrugated',\n",
       " 'paving stone',\n",
       " 'plan b with sand',\n",
       " 'plan b without sand',\n",
       " 'metal roof',\n",
       " 'planks',\n",
       " 'concrete sheets',\n",
       " 'galvanized sheets',\n",
       " 'grass thatch palm leaf',\n",
       " 'concrete slab cement',\n",
       " 'iron and tiles',\n",
       " 'palm bamboo grass',\n",
       " 'corrugated asbestos',\n",
       " 'ceramic brick tiles',\n",
       " 'corrugated iron sheet',\n",
       " 'thatch palm leaf grass',\n",
       " 'plastic pvc',\n",
       " 'sticks with mud and dung',\n",
       " 'mat',\n",
       " 'thatch palm leaves',\n",
       " 'skin',\n",
       " 'clay earthen cement',\n",
       " 'dung',\n",
       " 'plycem nicalit tiles',\n",
       " 'thatched palm leaf',\n",
       " 'thatch straw',\n",
       " 'galvanized sheet metal',\n",
       " 'not a dejure resident',\n",
       " 'rcc rbc',\n",
       " 't iron brick',\n",
       " 'wood bamboo',\n",
       " 'asbestos iron sheet',\n",
       " 'reinforced brick cement rcc',\n",
       " 't iron wood brick',\n",
       " 'iron sheets asbestos',\n",
       " 'cardboard plastic',\n",
       " 'cement rcc',\n",
       " 'sod grass',\n",
       " 'wood t iron mud',\n",
       " 'calamine fibre of cement',\n",
       " 'palm leaf thatched',\n",
       " 'bamboo or rustic mat with mud',\n",
       " 'bambu with mud',\n",
       " 'concrete plaque',\n",
       " 'not dejure resident',\n",
       " 'plaque from different materials',\n",
       " 'straw and palm leaves',\n",
       " 'estera',\n",
       " 'with no roof',\n",
       " 'carton',\n",
       " 'galvanized iron aluminum',\n",
       " 'makeshift cardboard',\n",
       " 'thatch palm leaf nipa',\n",
       " 'sod grass cogon',\n",
       " 'metal galvanized iron alumi',\n",
       " 'rustic mat plastic',\n",
       " 'metal iron sheet',\n",
       " 'thatch palm leaf leaf',\n",
       " 'zinc slates tile',\n",
       " 'tarpaulin',\n",
       " 'metalic sheets',\n",
       " 'corrugate iron',\n",
       " 'grass',\n",
       " 'sheet metal',\n",
       " 'banco',\n",
       " 'corrugated iron tole',\n",
       " 'concrete tile roof',\n",
       " 'aluminium',\n",
       " 'metal sheets',\n",
       " 'pavings',\n",
       " 'straws',\n",
       " 'taule tarred rough paper',\n",
       " 'metal zink',\n",
       " 'dal briq plan tuil',\n",
       " 'branch end ter toles',\n",
       " 'branch s enduit',\n",
       " 'grass leaves mud',\n",
       " 'grass thatch mud',\n",
       " 'thatched',\n",
       " 'iron tin',\n",
       " 'tins',\n",
       " 'thatch cane',\n",
       " 'grass straw',\n",
       " 'tile fibro asbestos',\n",
       " 'galvanized iron alu',\n",
       " 'cane and mud',\n",
       " 'concrete roof cement',\n",
       " 'metal plates',\n",
       " 'metal plates and mud',\n",
       " 'straw cane',\n",
       " 'wood and cement',\n",
       " 'wood and dirt',\n",
       " 'calamine cement fiber asbestors',\n",
       " 'metal iron sheets',\n",
       " 'ceramic tiles harvey tiles',\n",
       " 'calamine cement fiber asbestos',\n",
       " 'finished asbestos',\n",
       " 'finished metal',\n",
       " 'finished tiles',\n",
       " 'natural thatch',\n",
       " 'natural no roof']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.housing_roof.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define test globals\n",
    "DIGITS = str([str(x) for x in range(100 + 1)])\n",
    "PUNCT = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "SPACE = '     '\n",
    "\n",
    "# if you compile the regex string first, it's even faster\n",
    "re_dig = re.compile('\\d')\n",
    "re_punct = re.compile('\\W+')\n",
    "re_white = re.compile(' +')\n",
    "\n",
    "def test_globals():\n",
    "    \"\"\"This function tests that the test globals are properly defined.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(DIGITS) != None, \"Global doesn't contain digits!\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(PUNCT) != None, \"Global doesn't contain punctuation!\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(SPACE) != None, \"Global doesn't contain whitespace!\"\n",
    "    \n",
    "\n",
    "def test_clean_text():\n",
    "    \"\"\"This function tests that the clean text function is doing its job.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(prep.clean_text(DIGITS)) == None, \"clean_text did not remove the digits from test global.\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(prep.clean_text(PUNCT)) == None, \"clean_text did not remove the punctuation from test global.\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(prep.clean_text(SPACE)) == None, \"clean_text did not remove the whitespace from test global.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./tests/test_prep.py\n",
    "#write tests\n",
    "\"\"\"This is a module used to test a module: \"prep.py\" and its relevant functions read_then_clean and clean_text\n",
    "\n",
    "read_then_clean is a function that takes a csv with messy string values and \n",
    "creates then cleans a pandas df\n",
    "using clean_text\n",
    "\n",
    "This module tests that function by ensuring that it returns expected exceptions and\n",
    "does not contain unexpected values.\n",
    "\"\"\"\n",
    "# import packages\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#import custom modules fpr testing\n",
    "import prep.prep_data as prep\n",
    "\n",
    "#set globals for tests\n",
    "FILEPATH = '../data/housing_data.csv'\n",
    "CLEAN_COLS = ['housing_roof', 'housing_wall', 'housing_floor']\n",
    "DIGITS = str([str(x) for x in range(100 + 1)])\n",
    "PUNCT = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "SPACE = '     '\n",
    "\n",
    "# if you compile the regex string first, it's even faster\n",
    "re_dig = re.compile('\\d')\n",
    "re_punct = re.compile('\\W+')\n",
    "re_white = re.compile(' +')\n",
    "\n",
    "def test_globals():\n",
    "    \"\"\"This function tests that the test globals are properly defined.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(DIGITS) != None, \"global doesn't contain digits!\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(PUNCT) != None, \"global doesn't contain punctuation!\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(SPACE) != None, \"global doesn't contain whitespace!\"\n",
    "    \n",
    "\n",
    "def test_clean_text():\n",
    "    \"\"\"This function tests that the clean text function is doing its job.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(prep.clean_text(DIGITS)) == None, \"clean_text did not remove the digits from test global.\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(prep.clean_text(PUNCT)) == None, \"clean_text did not remove the punctuation from test global.\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(prep.clean_text(SPACE)) == None, \"clean_text did not remove the whitespace from test global.\"\n",
    "\n",
    "# This is our base dataset and it needs to be cleaned properly. The second argument specifies\n",
    "# the cols with string values that we want to be cleaned.\n",
    "\n",
    "\n",
    "#TODO, how to cause read_then_clean to raise the row count exception??\n",
    "def test_read_then_clean():\n",
    "    \"\"\"This function tests that a custom exception called RowCountException\n",
    "    will be returned when more than 1k rows are expected.\n",
    "    \"\"\"\n",
    "    with pytest.raises(Exception) as err:\n",
    "        test_df = prep.read_then_clean(FILEPATH,\n",
    "                                       CLEAN_COLS)\n",
    "    assert 'RowCountException' in str(err) #verify that your custom error is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file ./prep/prep_data.py\n",
    "#define necessary helper functions\n",
    "def clean_text(text):\n",
    "    \"\"\"This function is used to clean a selection of text. \n",
    "    It uses several regular expressions and built in text commands in order to remove commonly seen \n",
    "    errors,\n",
    "    nonsense values, \n",
    "    punctuation, \n",
    "    digits, and \n",
    "    extra whitespace.\n",
    "\n",
    "    Args:\n",
    "        text (str): This is a text value that needs to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        text: This function returns a cleaned version of the input text.\n",
    "        \n",
    "    TODO: Add functionality to impute a selected value for NaN or missing values?\n",
    "\n",
    "    \"\"\"\n",
    "    #import necessary modules\n",
    "    import re\n",
    "    \n",
    "    #force all vals in series to string\n",
    "    text = str(text)\n",
    "    \n",
    "    #first remove uppercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove common errors\n",
    "    text = re.sub(r\"\\[.]\", \"\", text) \n",
    "    text = re.sub(r\"\\<ff>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<fb>\", \"\", text)\n",
    "    text = re.sub(r\"\\<a\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<c\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<d\\d>\", \"\", text)\n",
    "    text = re.sub(r\"\\<e\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<f\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\d+\\.\", \"\", text)\n",
    "\n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)   \n",
    "\n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    \n",
    "    # remove any remaining digit codes\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    \n",
    "    # remove any leading/trailing/duplicate whitespace\n",
    "    text = re.sub(' +', ' ', text.strip())\n",
    "    \n",
    "    return text\n",
    "    \n",
    "#define master function\n",
    "def read_then_clean(file_path, vars_to_clean, filter_series=None):\n",
    "    \"\"\"This is the master function for this module. It uses the previously defined helper functions,\n",
    "    in order to output a clean dataset for user. It reads in a selected .csv file from a given filepath,\n",
    "    and applies the previously defined cleaning functions to a list of variables provided by user.\n",
    "    \n",
    "    It can also optionally filter the df based on the survey series or TODO language.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): This is a string indicating which file that you want to read in.\n",
    "        vars_to_clean (list): This is a list of strings that indicate which columns you want to clean.\n",
    "        filter_series (list): This is a list of strings that indicate which survey series to keep.\n",
    "\n",
    "    Returns:\n",
    "        df_clean: This is a pandas df that has columns of text values that have been cleaned using the helper function.\n",
    "        \n",
    "    TODO: Is it better to return an obj called df_clean to be more explicit to user?\n",
    "\n",
    "    \"\"\"\n",
    "    #import necessary modules\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    #read in your data\n",
    "    print(\"~begin reading\")\n",
    "    df_raw = pd.read_csv(file_path, low_memory=False)\n",
    "    min_nrow = len(df_raw) #save the row count to test after cleaning and verify that rows are not being dropped\n",
    "    print(\"data read!\")\n",
    "    \n",
    "    #cleanup\n",
    "    print(\"~begin cleaning\")\n",
    "    df_clean = df_raw.copy()\n",
    "    for var in vars_to_clean:\n",
    "        df_clean[var] = df_clean[var].apply(clean_text)\n",
    "    print(\"data clean!\")\n",
    "    \n",
    "    # Verify that the minimum rowcount continues to be met\n",
    "    if len(df_clean) < min_nrow:\n",
    "        class RowCountException(Exception):\n",
    "            \"\"\"Custom exception class.\n",
    "            \n",
    "            This exception is raised when the minimum row is unmet.\n",
    "\n",
    "            \"\"\"\n",
    "            pass\n",
    "        \n",
    "        raise RowCountException(\"Minimum number of rows were not returned after cleaning. Data is being lost!\")\n",
    "        \n",
    "    # Filter data if filter arguments are provided by user\n",
    "    if filter_series != None:\n",
    "        print(\"~applying filter\")\n",
    "        df_clean = df_clean[df_clean['survey_series'].isin(filter_series)]\n",
    "        \n",
    "    #output a clean dataset\n",
    "    return df_clean\n",
    "\n",
    "#define function to replace meaningless values with NaNs\n",
    "def remove_garbage_codes(df, vars_to_clean, garbage_list):\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # build dictionary to map all garbage values to NaN\n",
    "    garb_dict = {}\n",
    "    for string in garbage_list:\n",
    "        garb_dict[string] = \"replace me\"\n",
    "    \n",
    "    print(garb_dict)\n",
    "    \n",
    "    for var in vars_to_clean:\n",
    "        print(\"removing garbage from \", var)\n",
    "        df_clean[var] = df_clean[var].map(garb_dict).fillna(df_clean[var])\n",
    "        df_clean[var] = df_clean[var].replace(\"replace_me\", np.nan, inplace=True)\n",
    "        \n",
    "    #output a clean dataset\n",
    "    return df_clean    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraps\n",
    "DIGITS = str([str(x) for x in range(100 + 1)])\n",
    "PUNCT = \"xx\"\n",
    "#PUNCT = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "SPACE = '     '\n",
    "\n",
    "(DIGITS)\n",
    "test_globals()\n",
    "#look at some of the clean values\n",
    "df_raw.housing_floor.unique().tolist()\n",
    "clean_text('32. vinyl_asphalt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
