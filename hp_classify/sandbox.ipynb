{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SANDBOX for code development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "#import custom modules\n",
    "import prep.prep_data as prep\n",
    "import prep.prep_cv as cv\n",
    "import model.fuzzy as fz\n",
    "\n",
    "#magik\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup globals\n",
    "#setup directories\n",
    "CWD = os.getcwd()\n",
    "HOME_DIR = os.path.abspath(os.path.join(CWD, os.pardir))\n",
    "DATA_DIR = HOME_DIR + \"/data\"\n",
    "DATA_FILENAME = \"housing_data.csv\"\n",
    "RESULTS_DIR = HOME_DIR + \"/results\"\n",
    "\n",
    "#setup lists of vars to work with\n",
    "STR_VARS = ['housing_roof', 'housing_wall', 'housing_floor']\n",
    "NUM_VARS = [s + '_num' for s in STR_VARS]\n",
    "RANK_VARS = [s + '_rank' for s in STR_VARS]\n",
    "\n",
    "#which variable do you want to predict (currently: floor/wall/roof)\n",
    "DEP_VAR = \"housing_roof\"\n",
    "PRED_VAR = DEP_VAR + \"_rank\" #will always be using the strings to predict ranking\n",
    "\n",
    "#setup a filter to select which surveys you want to work with\n",
    "SVY_FILTER = ['MACRO_DHS']\n",
    "\n",
    "#analytical options\n",
    "CV_SAMPLE_PCT = .2 #hold out x% for testing\n",
    "CV_SAMPLE_WT = \"N\" #which variable(if any) shall weight your test sample\n",
    "CV_FOLDS = 2 #use a x-fold cross-validation env\n",
    "\n",
    "#garbage lists\n",
    "STR_GARBAGE = ['nan', 'other', 'not a dejure resident', 'not dejure resident']\n",
    "RANK_GARBAGE = ['4', '5', '6', '7', '8', '9', 'n']\n",
    "\n",
    "#dictionaries\n",
    "PRED_DICT = {'natural':'1', 'rudimentary':'2', 'finished':'3'} #map categories back to ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~begin reading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read!\n~begin cleaning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data clean!\n~applying filter\n"
     ]
    }
   ],
   "source": [
    "df = prep.read_then_clean(DATA_DIR + \"/\" + DATA_FILENAME, STR_VARS, SVY_FILTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nan': nan, 'other': nan, 'not a dejure resident': nan, 'not dejure resident': nan}\nremoving garbage from  housing_roof\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing garbage from  housing_wall\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing garbage from  housing_floor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining ranking for  housing_roof_num\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining ranking for  housing_wall_num\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining ranking for  housing_floor_num\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4': nan, '5': nan, '6': nan, '7': nan, '8': nan, '9': nan, 'n': nan}\nremoving garbage from  housing_roof_rank\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing garbage from  housing_wall_rank\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing garbage from  housing_floor_rank\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling df, iteration # 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling df, iteration # 1\n"
     ]
    }
   ],
   "source": [
    "df_clean = prep.remove_garbage_codes(df, STR_VARS, STR_GARBAGE)\n",
    "df_clean = prep.extract_ranking(df_clean, NUM_VARS)\n",
    "df_clean = prep.remove_garbage_codes(df_clean, RANK_VARS, RANK_GARBAGE)\n",
    "train_list = cv.cv_censor_col(df_clean, PRED_VAR, CV_SAMPLE_PCT, CV_SAMPLE_WT, CV_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='cv loop', max=2, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on cv loop # 0\n",
      "building corpus for rank # 1\n",
      "building corpus for rank # 2\n",
      "building corpus for rank # 3\n",
      "extracting unknown strings\n",
      "need to classify 289 unknown strings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='classifying unknown strings', max=289, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing... cement bricks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sod mud with grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch bushes grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood timber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ceramic tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rustic mat mud with hay\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood planks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... roofing shingles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mud and hay\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamine cement fiber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rustic mat\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc plates\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass palm\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete slab\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... no roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cardboard\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... reinforced concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tuale tarred roofing paper\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ruberoid asbest\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... slate\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tol kir\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete panels\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tuiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... vegetal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... autre\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metallique\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... local tiling\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc cement fiber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sod\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... earth\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tole\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tuile\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tile tole\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... leaves\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm branches\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tile tuile\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palms bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tile\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... stone slabs\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... jute bamboo mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tin\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... katcha bamboo thatch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement concrete tiled\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... earth bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... roof tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw cane palms\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamine\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm tree\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concret\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamina plancha\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tiles teja\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... losade hormigon armado\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cane palm mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... eternit amianto\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... polished wood\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... clay tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... raw wood\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm straw\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tuiles ardoise eternit\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... chaume palme feuilles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tle\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palme bambou\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... planches en bois\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natte\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tiles slate\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... paille chaume natte\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... yagua\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... carton zinc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbest cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbest tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bamboo cane\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm leaves cana\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm tree yagua\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tiles tejas\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plywood\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbesto\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cana\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm leave\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... reed bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rustic mat plastic sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood or mulch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... reed or bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement or concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch leaf mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos cement fiber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal corrugated iron\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron sheet ceiling\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron sheet only\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic carton used metal sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw branch palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal only\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic cardboard\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal and ceiling\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bark straw palm bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... aluminum iron sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos slate roofing sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ceramic tiles brick tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished asbestos slate roofing sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished zinc aluminium\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary cardboard\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished ceramic brick tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished wood\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary rustic mat\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural thatch palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural mud sod\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished calamine cement fiber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished roofing shingles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~>corpus# 2\n",
      "analyzing... rudimentary palm bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary wood planks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... slab\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement fiber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw palm\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tile mud ceramic concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... no walls\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mud tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thach palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... no roofing\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... waste material\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... canvas tent\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... shingles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos zinc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... brick concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal zinc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaf sod\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood sirap\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal gi\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rcc rbc cement concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic polythene sheeting\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... raw wood planks timber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sod mud and grass mixture\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... unburnt bricks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... burnt brick\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... loosely packed stone\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos wood zinc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mud bricks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mud bricks with stones\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass thatch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron mabati\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass thatch makuti\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tin cans\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corregated iron mabati\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... dung mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... iron sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch grass makuti\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... dung mud sod\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement beton blocks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tar\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... galvanized iron aluminium\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm bamboo bark\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tiles cement concrete fibrous\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic sheet tent\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm bamboo thatch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bamboo thatch palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asphalt asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tarpaulin plastic\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos sheets shingles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm bamboo mats\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc metal aluminum\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cadjan palmayra strw\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... waste materials\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished roofing metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural roofing thatch grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... roofing tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary roofing wood planks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal corrugated\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ceramic clay tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... paving stone\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plan b with sand\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plan b without sand\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... planks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... galvanized sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass thatch palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete slab cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... iron and tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm bamboo grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaf grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic pvc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ceramic brick tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mat\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaves\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... skin\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... clay earthen cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... dung\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plycem nicalit tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatched palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch straw\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... galvanized sheet metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... t iron brick\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos iron sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rcc rbc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... reinforced brick cement rcc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... t iron wood brick\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... iron sheets asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cardboard plastic\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement rcc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood t iron mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sod grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm leaf thatched\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bamboo or rustic mat with mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamine fibre of cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete plaque\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plaque from different materials\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw and palm leaves\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... estera\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... with no roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bambu with mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... carton\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... galvanized iron aluminum\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaf nipa\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... makeshift cardboard\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sod grass cogon\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal galvanized iron alumi\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rustic mat plastic\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal iron sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaf leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc slates tile\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tarpaulin\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metalic sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~>corpus# 2\n",
      "analyzing... grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugate iron\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sheet metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron tole\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... banco\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... aluminium\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straws\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... pavings\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... taule tarred rough paper\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal zink\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... dal briq plan tuil\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... branch end ter toles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass leaves mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass thatch mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatched\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch cane\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass straw\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tile fibro asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... galvanized iron alu\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cane and mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete roof cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood and cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood and dirt\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw cane\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal plates and mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal plates\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamine cement fiber asbestors\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal iron sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ceramic tiles harvey tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamine cement fiber asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural thatch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural no roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "working on cv loop # 1\n",
      "building corpus for rank # 1\n",
      "building corpus for rank # 2\n",
      "building corpus for rank # 3\n",
      "extracting unknown strings\n",
      "need to classify 283 unknown strings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='classifying unknown strings', max=283, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing... rustic mat mud with hay\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sod mud with grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch bushes grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood timber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement bricks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ceramic tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... roofing shingles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood planks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... no roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mud and hay\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rustic mat\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamine cement fiber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc plates\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass palm\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete slab\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cardboard\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... reinforced concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tuale tarred roofing paper\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ruberoid asbest\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... slate\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tol kir\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete panels\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tuiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... vegetal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... autre\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metallique\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... local tiling\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc cement fiber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sod\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tiles slate\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tole\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tuile\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tile tole\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... leaves\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm branches\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... earth\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palms bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tile\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... stone slabs\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... shingles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... jute bamboo mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tin\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... katcha bamboo thatch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement concrete tiled\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... earth bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... roof tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw cane palms\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamine\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm tree\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concret\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamina plancha\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tiles teja\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... losade hormigon armado\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cane palm mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... eternit amianto\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... polished wood\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... clay tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm straw\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... raw wood\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tle\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tuiles ardoise eternit\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... chaume palme feuilles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palme bambou\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... paille chaume natte\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbest cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... carton zinc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... yagua\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bamboo cane\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbest tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm tree yagua\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm leaves cana\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plywood\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cana\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm leave\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbesto\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rustic mat plastic sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... reed bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood or mulch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... reed or bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement or concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch leaf mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos cement fiber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal corrugated iron\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron sheet ceiling\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron sheet only\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw branch palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic carton used metal sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tiles slates\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal only\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal and ceiling\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bark straw palm bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic cardboard\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... aluminum iron sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos slate roofing sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished asbestos slate roofing sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished zinc aluminium\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary cardboard\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary palm bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished ceramic brick tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural thatch palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished roofing shingles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary wood planks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished wood\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural mud sod\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary rustic mat\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished calamine cement fiber\n",
      "~>corpus# 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... slab\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tile mud ceramic concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement fiber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw palm\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... no walls\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mud tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... no roofing\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thach palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... waste material\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... canvas tent\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos zinc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... brick concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal zinc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaf sod\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood sirap\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal gi\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic polythene sheeting\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rcc rbc cement concrete\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... burnt brick\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... raw wood planks timber\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sod mud and grass mixture\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... loosely packed stone\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... unburnt bricks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos wood zinc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mud bricks with stones\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass thatch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron mabati\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass thatch makuti\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tin cans\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corregated iron mabati\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... dung mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... iron sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch grass makuti\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... dung mud sod\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement beton blocks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tar\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... galvanized iron aluminium\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm bamboo bark\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tiles cement concrete fibrous\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic sheet tent\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm bamboo thatch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bamboo thatch palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asphalt asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos sheets shingles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm bamboo mats\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tarpaulin plastic\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc metal aluminum\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cadjan palmayra strw\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... waste materials\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished roofing metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural roofing thatch grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... roofing tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rudimentary roofing wood planks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal corrugated\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ceramic clay tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... paving stone\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plan b with sand\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plan b without sand\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... planks\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... galvanized sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass thatch palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete slab cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm bamboo grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaf grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ceramic brick tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sticks with mud and dung\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plastic pvc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... mat\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaves\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... skin\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... clay earthen cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plycem nicalit tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatched palm leaf\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... dung\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch straw\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... galvanized sheet metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood bamboo\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rcc rbc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... t iron brick\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... asbestos iron sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... t iron wood brick\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... reinforced brick cement rcc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... iron sheets asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cardboard plastic\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cement rcc\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood t iron mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sod grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamine fibre of cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... palm leaf thatched\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bamboo or rustic mat with mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete plaque\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... plaque from different materials\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw and palm leaves\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... bambu with mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... estera\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... with no roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... carton\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... galvanized iron aluminum\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... makeshift cardboard\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sod grass cogon\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch palm leaf nipa\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal galvanized iron alumi\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... rustic mat plastic\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal iron sheet\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... zinc slates tile\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tarpaulin\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metalic sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugate iron\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... sheet metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... corrugated iron tole\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... banco\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete tile roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~>corpus# 2\n",
      "analyzing... metal sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... aluminium\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... pavings\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straws\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... taule tarred rough paper\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal zink\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... dal briq plan tuil\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass leaves mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass thatch mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatched\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... thatch cane\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... tile fibro asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... grass straw\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... galvanized iron alu\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... cane and mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... concrete roof cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood and cement\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... wood and dirt\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal plates and mud\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... straw cane\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal plates\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamine cement fiber asbestors\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... metal iron sheets\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... calamine cement fiber asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... ceramic tiles harvey tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished asbestos\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural thatch\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished metal\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... finished tiles\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "analyzing... natural no roof\n",
      "~>corpus# 0\n",
      "~>corpus# 1\n",
      "~>corpus# 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run your cross-validation analysis\n",
    "cv_distrib, cv_preds, cv_results, cv_df = fuzzy_cv(train_list, DEP_VAR, PRED_DICT)\n",
    "\n",
    "#output the results to csv\n",
    "# save_results_df(cv_results, out_dir, \"cv_results\")\n",
    "# save_results_df(cv_preds, out_dir, \"cv_preds\")\n",
    "# save_results_df(cv_df, out_dir, \"cv_df\")\n",
    "# save_results_df(cv_distrib, out_dir, \"cv_distrib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loop over all cross-validation results and plot them in chunks of 26 (4colsx6rows)\n",
    "\n",
    "#plot results\n",
    "fz.fuzzy_density(cv_distribi wou, 'word', \n",
    "                 ['natural', 'rudimentary', 'finished'],\n",
    "                 color_list={'natural':'r', 'rudimentary':'b', 'finished':'g'},\n",
    "                 cutoff=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_to_pdf(df, graph, graph_dir, graph_filename, graph_title):\n",
    "    \"\"\"\n",
    "    This is a demo of creating a pdf file with several pages,\n",
    "    as well as adding metadata and annotations to pdf files.\n",
    "    \"\"\"\n",
    "\n",
    "    import datetime\n",
    "    import numpy as np\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    #build filepath\n",
    "    pdf_filepath = graph_dir + \"/\" + graph_filename\n",
    "\n",
    "    # Create the PdfPages object to which we will save the pages:\n",
    "    # The with statement makes sure that the PdfPages object is closed properly at\n",
    "    # the end of the block, even if an Exception occurs.\n",
    "    with PdfPages(pdf_filepath) as pdf:\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.title(graph_title)\n",
    "        pdf.savefig(graph)  # or you can pass a Figure object to pdf.savefig\n",
    "        plt.close()\n",
    "\n",
    "        # We can also set the file's metadata via the PdfPages object:\n",
    "        d = pdf.infodict()\n",
    "        d['Title'] = 'Multipage PDF Example'\n",
    "        d['Author'] = u'Jouni K. Sepp\\xe4nen'\n",
    "        d['Subject'] = 'How to create a multipage pdf file and set its metadata'\n",
    "        d['Keywords'] = 'PdfPages multipage keywords author title subject'\n",
    "        d['CreationDate'] = datetime.datetime(2009, 11, 13)\n",
    "        d['ModDate'] = datetime.datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file ./model/cv.py\n",
    "\n",
    "def fuzzy_cv(cv_list, base_var, rank_dictionary, subset=None, threshold=75):\n",
    "\n",
    "    #import packages\n",
    "    from fuzzywuzzy import fuzz\n",
    "    from fuzzywuzzy import process\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm_notebook\n",
    "\n",
    "    #import custom modules\n",
    "    import model.fuzzy as fz\n",
    "    \n",
    "    #setup objects\n",
    "    rank_var = base_var + '_rank'\n",
    "    og_var = rank_var + '_og'\n",
    "    \n",
    "    #TODO validate syntax\n",
    "    rank_values = list(rank_dictionary.values())\n",
    "    rank_keys = list(rank_dictionary.keys())\n",
    "    \n",
    "    #create lists to store loop outputs\n",
    "    cv_distrib = []\n",
    "    cv_preds = []\n",
    "    cv_results = []\n",
    "    cv_df = []\n",
    "    \n",
    "    #loop over each cross validation:\n",
    "    for i in tqdm_notebook(range(len(cv_list)), desc=\"cv loop\"):\n",
    "        \n",
    "        print('working on cv loop #', i)\n",
    "        df = cv_list[i].copy() #subset the cv list to the current df\n",
    "\n",
    "        #build corpus of known and unknown strings\n",
    "        str_list, idk_strings = fz.build_corpus(df, base_var, rank_var, rank_values)\n",
    "        \n",
    "        #subset the unknown strings to allow for faster testing\n",
    "        if subset != None:\n",
    "            idk_strings = idk_strings[subset]\n",
    "        \n",
    "        #find distribution of scores for each string\n",
    "        distrib = fz.fuzzy_scan(idk_strings, str_list)\n",
    "        \n",
    "        #TODO, output plots of distribution for analysis\n",
    "\n",
    "        \n",
    "        #predict class based on probability of exceeding similarity cutoff\n",
    "        preds = fz.fuzzy_predict(distrib, rank_keys, 'word', threshold,\n",
    "                                 rank_dictionary)\n",
    "\n",
    "        #merge results back on the test data to validate\n",
    "        out = df[df['train']==0]\n",
    "        out = pd.merge(out,\n",
    "                       preds,\n",
    "                       left_on=base_var,\n",
    "                       right_on='word',\n",
    "                       how='left')\n",
    "\n",
    "        #calculate success rate and tabulate\n",
    "        out['success'] = np.where(out[og_var] == out['pred'], 1, 0)\n",
    "        success_rate = pd.crosstab(out[~pd.isnull(out['pred'])]['success'], columns='count')\n",
    "        \n",
    "        #append results to prep for next loop\n",
    "        cv_distrib.append(distrib)\n",
    "        cv_preds.append(preds)\n",
    "        cv_results.append(success_rate)\n",
    "        cv_df.append(out)\n",
    "        \n",
    "    return(cv_distrib, cv_preds, cv_results, cv_df)\n",
    "\n",
    "\n",
    "def save_results_df(df, out_dir, out_name):\n",
    "    \n",
    "    out_path = f'{out_dir}//{out_name}.csv'    \n",
    "    print('saving df to', out_path)\n",
    "    \n",
    "    df = pd.concat(df)\n",
    "    df.to_csv(out_path, header=False, sep=';')\n",
    "    \n",
    "    return(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./model/fuzzy.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./model/fuzzy.py\n",
    "\n",
    "#define function to replace meaningless values with NaNs\n",
    "# def extract_ranking(df, vars_to_clean):\n",
    "#     \"\"\"This helper function is used to \n",
    "\n",
    "#     Args:\n",
    "#     df (pandas df): This is a pandas df that has \n",
    "#     dep_var (str): This is the name of a column\n",
    "\n",
    "#     Returns:\n",
    "#         df_out: \n",
    "        \n",
    "#     TODO: ?\n",
    "\n",
    "#     \"\"\"\n",
    "        \n",
    "#     df_out = df.copy()\n",
    "\n",
    "#     #output a clean dataset\n",
    "#     return \n",
    "\n",
    "def build_corpus(df, str_var, rank_var, rank_list):\n",
    "    \n",
    "    #import necessary modules\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from fuzzywuzzy import fuzz\n",
    "    from fuzzywuzzy import process\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    for x in rank_list:\n",
    "        print(\"building corpus for rank #\", x)\n",
    "        out.append(df[df[rank_var]==x][str_var].values)    \n",
    "\n",
    "    print(\"extracting unknown strings\")\n",
    "    other = df[~df[rank_var].isin(rank_list)][str_var].unique()\n",
    "    other = other[~pd.isnull(other)] #cant classify NaN\n",
    "    print(\"need to classify\", len(other), \"unknown strings\")\n",
    "\n",
    "    return(out, other)\n",
    "\n",
    "def fuzzy_scan(unknown_list, corpus_list):\n",
    "    \n",
    "    #import necessary modules\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from fuzzywuzzy import fuzz\n",
    "    from fuzzywuzzy import process\n",
    "    from tqdm import tqdm_notebook\n",
    "\n",
    "    distrib = []\n",
    "\n",
    "    #loop over each unknown string\n",
    "    for x in tqdm_notebook(range(len(unknown_list)), desc=\"classifying unknown strings\", leave=False): \n",
    "        unknown_str = unknown_list[x]\n",
    "        print('analyzing...', unknown_str)\n",
    "\n",
    "        out = []\n",
    "        #loop over each corpus to compute similarity scores for all words in a given housing quality score\n",
    "        for y in range(len(corpus_list)):\n",
    "            print('~>corpus#', y)\n",
    "            corpus = corpus_list[y]\n",
    "\n",
    "\n",
    "            scores = []\n",
    "            #loop over each word and compute the similarity score\n",
    "            for z in range(len(corpus)):\n",
    "                scores.append(fuzz.WRatio(unknown_str, corpus[z]))\n",
    "\n",
    "            out.append(scores) #append scores to create a distribution for the entire corpus\n",
    "\n",
    "        #append distributions of scores\n",
    "        distrib.append(pd.DataFrame({'word': unknown_str, \n",
    "                                     'natural':pd.Series(out[0]), \n",
    "                                     'rudimentary':pd.Series(out[1]), \n",
    "                                     'finished':pd.Series(out[2]) #note series method used to overcome differing lengths\n",
    "                                    }))\n",
    "\n",
    "\n",
    "    return(pd.concat(distrib))\n",
    "\n",
    "def fuzzy_predict(df, var_list, grouping, cutoff, dictionary):\n",
    "    \n",
    "    #calculate the probability that a classification score exceeds cutoff\n",
    "    out = df.groupby(grouping)[var_list].apply(lambda c: (c>cutoff).sum()/len(c))\n",
    "    \n",
    "    #return column w/ max value and map to rank with dictionary\n",
    "    out['pred'] = out[var_list].idxmax(axis=1).map(dictionary) \n",
    "    \n",
    "    return(out)\n",
    "\n",
    "def fuzzy_transform(df, var_list, grouping, fx, stub):\n",
    "\n",
    "    for var in var_list:\n",
    "\n",
    "        print('calculating prob for...', var)\n",
    "\n",
    "        kwargs = {var+stub : lambda x: x[var]/x.groupby(grouping)[var].transform(fx)}\n",
    "        df = df.assign(**kwargs)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "def fuzzy_density(df, facet, var_list, color_list, variant=\"\", cutoff=None):\n",
    "    \n",
    "    #import necessary modules\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "\n",
    "    g = sns.FacetGrid(df, col=facet, col_wrap=5, height=3)\n",
    "\n",
    "    for var in var_list:\n",
    "        ('plotting...', var)\n",
    "        g = g.map(sns.kdeplot, var+variant, shade=True, color=color_list[var])\n",
    "        \n",
    "        #add cutoff line if provided\n",
    "        if cutoff != None:\n",
    "            g = g.map(plt.axvline, x=cutoff, color='grey', linestyle='dashed')\n",
    "        \n",
    "    g = g.add_legend()\n",
    "    \n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./prep/prep_cv.py\n",
    "\n",
    "#define necessary helper functions\n",
    "def cv_censor_col(df, colname, pct=.2, weight_var=None, reps=5):\n",
    "    \n",
    "    \"\"\"This function is used to create pandas dfs where a specified % of the values in a column have been censored\n",
    "    and replaced with NaN, so that they can be predicted in a cross-validation methodology. It returns a list of such\n",
    "    dfs that is the length of the reps argument.\n",
    "\n",
    "    Args:\n",
    "        df (pandas df): This is a pandas df that has columns with garbage values to be removed.\n",
    "        colname (str): This is a string indicating the name of a column that you want to censor and later predict.\n",
    "        pct (float): This is a value between 0-1 that indicates the fraction of values you want to censor. Default = 20%\n",
    "        weight_var (str): This is a string indicating the column name is used to weighted the sample. Default = No weight.\n",
    "        reps (int): This is an integer indicating the number of different training datasets to create. Default = 5x\n",
    "\n",
    "    Returns:\n",
    "        df_clean: This function returns a pandas df where the garbage codes have been replaced with NaN.\n",
    "        \n",
    "    TODO: ?\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #import packages\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    for x in range(reps):\n",
    "            \n",
    "        print(\"sampling df, iteration #\", x)\n",
    "    \n",
    "        #first archive your old column in order to test later\n",
    "        new_df = df.copy()\n",
    "        new_df[colname + '_og'] = new_df[colname]\n",
    "        new_df['train'] = 1 #set column to specify whether training or test data\n",
    "\n",
    "        #draw a weighted sample if weight var is specified\n",
    "        if weight_var != None:\n",
    "            df_censor = new_df.sample(frac=pct, weights=weight_var)\n",
    "        else:\n",
    "            df_censor = new_df.sample(frac=pct)\n",
    "            \n",
    "        #now replace the sampled column with missing values in order to try and predict\n",
    "        #note that replacement is only done on the sampled indices\n",
    "        df_censor['train'] = 0 #note that this sample is no longer training data (it is test)\n",
    "        df_censor[colname] = \"replace_me\"\n",
    "        new_df.update(df_censor, overwrite=True)\n",
    "        new_df[colname].replace(\"replace_me\", np.nan, inplace=True)\n",
    "        #TODO unsure if this is pythonic method but it seems like df.update won't replace values with NaN, \n",
    "        #as such, need to do this workaround\n",
    "        \n",
    "        #store the result (df with columns censored)\n",
    "        out.append(new_df)\n",
    "    \n",
    "    #return the list of sampled dfs\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./prep/prep_data.py\n",
    "#define necessary helper functions\n",
    "def clean_text(text):\n",
    "    \"\"\"This function is used to clean a selection of text. \n",
    "    It uses several regular expressions and built in text commands in order to remove commonly seen \n",
    "    errors,\n",
    "    nonsense values, \n",
    "    punctuation, \n",
    "    digits, and \n",
    "    extra whitespace.\n",
    "\n",
    "    Args:\n",
    "        text (str): This is a text value that needs to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        text: This function returns a cleaned version of the input text.\n",
    "        \n",
    "    TODO: Add functionality to impute a selected value for NaN or missing values?\n",
    "\n",
    "    \"\"\"\n",
    "    #import necessary modules\n",
    "    import re\n",
    "    \n",
    "    #force all vals in series to string\n",
    "    text = str(text)\n",
    "    \n",
    "    #first remove uppercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove common errors\n",
    "    text = re.sub(r\"\\[.]\", \"\", text) \n",
    "    text = re.sub(r\"\\<ff>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<fb>\", \"\", text)\n",
    "    text = re.sub(r\"\\<a\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<c\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<d\\d>\", \"\", text)\n",
    "    text = re.sub(r\"\\<e\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<f\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\d+\\.\", \"\", text)\n",
    "\n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)   \n",
    "\n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    \n",
    "    # remove any remaining digit codes\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    \n",
    "    # remove any leading/trailing/duplicate whitespace\n",
    "    text = re.sub(' +', ' ', text.strip())\n",
    "    \n",
    "    return text\n",
    "    \n",
    "#define master function\n",
    "def read_then_clean(file_path, vars_to_clean, filter_series=None):\n",
    "    \"\"\"This is the master function for this module. It uses the previously defined helper functions,\n",
    "    in order to output a clean dataset for user. It reads in a selected .csv file from a given filepath,\n",
    "    and applies the previously defined cleaning functions to a list of variables provided by user.\n",
    "    \n",
    "    It can also optionally filter the df based on the survey series or TODO language.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): This is a string indicating which file that you want to read in.\n",
    "        vars_to_clean (list): This is a list of strings that indicate which columns you want to clean.\n",
    "        filter_series (list): This is a list of strings that indicate which survey series to keep.\n",
    "\n",
    "    Returns:\n",
    "        df_clean: This is a pandas df that has columns of text values that have been cleaned using the helper function.\n",
    "        \n",
    "    TODO: Is it better to return an obj called df_clean to be more explicit to user?\n",
    "\n",
    "    \"\"\"\n",
    "    #import necessary modules\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    #read in your data\n",
    "    print(\"~begin reading\")\n",
    "    df_raw = pd.read_csv(file_path, low_memory=False)\n",
    "    min_nrow = len(df_raw) #save the row count to test after cleaning and verify that rows are not being dropped\n",
    "    print(\"data read!\")\n",
    "    \n",
    "    #cleanup\n",
    "    print(\"~begin cleaning\")\n",
    "    df_clean = df_raw.copy()\n",
    "    for var in vars_to_clean:\n",
    "        df_clean[var] = df_clean[var].apply(clean_text)\n",
    "    print(\"data clean!\")\n",
    "    \n",
    "    # Verify that the minimum rowcount continues to be met\n",
    "    if len(df_clean) < min_nrow:\n",
    "        class RowCountException(Exception):\n",
    "            \"\"\"Custom exception class.\n",
    "            \n",
    "            This exception is raised when the minimum row is unmet.\n",
    "\n",
    "            \"\"\"\n",
    "            pass\n",
    "        \n",
    "        raise RowCountException(\"Minimum number of rows were not returned after cleaning. Data is being lost!\")\n",
    "        \n",
    "    # Filter data if filter arguments are provided by user\n",
    "    if filter_series != None:\n",
    "        print(\"~applying filter\")\n",
    "        df_clean = df_clean[df_clean['survey_series'].isin(filter_series)]\n",
    "        \n",
    "    #output a clean dataset\n",
    "    return df_clean\n",
    "\n",
    "#define function to replace meaningless values with NaNs\n",
    "def remove_garbage_codes(df, vars_to_clean, garbage_list):\n",
    "    \"\"\"This helper function is used to remove garbage values from a pandas df, replacing them with NaN.\n",
    "\n",
    "    Args:\n",
    "    df (pandas df): This is a pandas df that has columns with garbage values to be removed.\n",
    "    vars_to_clean (list): This is a list of strings that indicate which columns you want to clean.\n",
    "    garbage_list (list): This is a list of strings that indicate which garbage values to replace with NaN\n",
    "\n",
    "    Returns:\n",
    "        df_clean: This function returns a pandas df where the garbage codes have been replaced with NaN.\n",
    "        \n",
    "    TODO: set up an inverse argument so you can have opt to pass acceptable codes and NaN all others\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #import necessary modules\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # build dictionary to map all garbage values to NaN\n",
    "    garb_dict = {}\n",
    "    for string in garbage_list:\n",
    "        garb_dict[string] = np.nan\n",
    "    \n",
    "    print(garb_dict)\n",
    "    \n",
    "    for var in vars_to_clean:\n",
    "        print(\"removing garbage from \", var)\n",
    "        df_clean[var].replace(garb_dict, inplace=True)\n",
    "        \n",
    "    #output a clean dataset\n",
    "    return df_clean\n",
    "\n",
    "#define function to replace meaningless values with NaNs\n",
    "def extract_ranking(df, vars_to_clean):\n",
    "    \"\"\"This helper function is used to extract the ordinal rankings from numerical coding.\n",
    "\n",
    "    Args:\n",
    "    df (pandas df): This is a pandas df that has columns with garbage values to be removed.\n",
    "    vars_to_rank (list): This is a list of strings that indicate which columns you want to extract ranks from.\n",
    "\n",
    "    Returns:\n",
    "        df_out: This function returns a pandas df with new vars added with the ordinal rank cols defined.\n",
    "        \n",
    "    TODO: ?\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #import necessary modules\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    \n",
    "    for var in vars_to_clean:\n",
    "        print(\"defining ranking for \", var)\n",
    "        newcol = re.sub(\"_num\", \"_rank\", var) \n",
    "        df_out[newcol] = df_out[var].astype(str).str[0]\n",
    "\n",
    "    #output a clean dataset\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./tests/test_prep.py\n",
    "#write tests\n",
    "\"\"\"This is a module used to test a module: \"prep.py\" and its relevant functions read_then_clean and clean_text\n",
    "\n",
    "read_then_clean is a function that takes a csv with messy string values and \n",
    "creates then cleans a pandas df\n",
    "using clean_text\n",
    "\n",
    "This module tests that function by ensuring that it returns expected exceptions and\n",
    "does not contain unexpected values.\n",
    "\"\"\"\n",
    "# import packages\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#import custom modules fpr testing\n",
    "import prep.prep_data as prep\n",
    "\n",
    "#set globals for tests\n",
    "FILEPATH = '../data/housing_data.csv'\n",
    "CLEAN_COLS = ['housing_roof', 'housing_wall', 'housing_floor']\n",
    "DIGITS = str([str(x) for x in range(100 + 1)])\n",
    "PUNCT = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "SPACE = '     '\n",
    "\n",
    "# if you compile the regex string first, it's even faster\n",
    "re_dig = re.compile('\\d')\n",
    "re_punct = re.compile('\\W+')\n",
    "re_white = re.compile(' +')\n",
    "\n",
    "def test_globals():\n",
    "    \"\"\"This function tests that the test globals are properly defined.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(DIGITS) != None, \"global doesn't contain digits!\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(PUNCT) != None, \"global doesn't contain punctuation!\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(SPACE) != None, \"global doesn't contain whitespace!\"\n",
    "    \n",
    "\n",
    "def test_clean_text():\n",
    "    \"\"\"This function tests that the clean text function is doing its job.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(prep.clean_text(DIGITS)) == None, \"clean_text did not remove the digits from test global.\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(prep.clean_text(PUNCT)) == None, \"clean_text did not remove the punctuation from test global.\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(prep.clean_text(SPACE)) == None, \"clean_text did not remove the whitespace from test global.\"\n",
    "\n",
    "# This is our base dataset and it needs to be cleaned properly. The second argument specifies\n",
    "# the cols with string values that we want to be cleaned.\n",
    "\n",
    "\n",
    "#TODO, how to cause read_then_clean to raise the row count exception??\n",
    "def test_read_then_clean():\n",
    "    \"\"\"This function tests that a custom exception called RowCountException\n",
    "    will be returned when more than 1k rows are expected.\n",
    "    \"\"\"\n",
    "    with pytest.raises(Exception) as err:\n",
    "        test_df = prep.read_then_clean(FILEPATH,\n",
    "                                       CLEAN_COLS)\n",
    "    assert 'RowCountException' in str(err) #verify that your custom error is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraps\n",
    "DIGITS = str([str(x) for x in range(100 + 1)])\n",
    "PUNCT = \"xx\"\n",
    "#PUNCT = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "SPACE = '     '\n",
    "\n",
    "(DIGITS)\n",
    "test_globals()\n",
    "#look at some of the clean values\n",
    "df_raw.housing_floor.unique().tolist()\n",
    "clean_text('32. vinyl_asphalt')\n",
    "print_vars = ['iso3', 'int_year', 'housing_roof', 'housing_roof_rank', 'housing_roof_rank_og', 'train']\n",
    "obj = train_list[1]\n",
    "obj[print_vars].sample(50)\n",
    "#command scraps\n",
    "#pd.crosstab(train_list[1]['housing_wall_rank'], columns='count')\n",
    "\n",
    "\n",
    "#fuzzy_scan scraps\n",
    "distrib = []\n",
    "match = []\n",
    "\n",
    "for x in range(len(idk_strings[1:50])): \n",
    "    unknown_string = idk_strings[x]\n",
    "    print('analyzing...', unknown_string)\n",
    "    \n",
    "    #set lists to store loop results\n",
    "    nat = []\n",
    "    rud = []\n",
    "    fin = []\n",
    "               \n",
    "    for y in range(len(nat_strings)):\n",
    "        nat.append(fuzz.WRatio(unknown_string, nat_strings[y]))\n",
    "        rud.append(fuzz.WRatio(unknown_string, rud_strings[y]))\n",
    "        fin.append(fuzz.WRatio(unknown_string, fin_strings[y]))\n",
    "    \n",
    "    #append distributions of scores\n",
    "    distrib.append(pd.DataFrame({'word': unknown_string, 'natural':nat, 'rudimentary':rud, 'finished':fin}))\n",
    "    \n",
    "    #pull best matches\n",
    "    #note that extractOne returns an array, first item is match/second the ratio\n",
    "    match.append(pd.DataFrame({'word': unknown_string, \n",
    "                               'natural':process.extractOne(unknown_string, nat_strings)[0], \n",
    "                               'rudimentary':process.extractOne(unknown_string, rud_strings)[0], \n",
    "                               'finished':process.extractOne(unknown_string, fin_strings)[0]}, \n",
    "                              index=[0])) \n",
    "\n",
    "distrib = pd.concat(distrib)\n",
    "distrib = fuzzy_transform(distrib, ['natural', 'rudimentary', 'finished'], 'word', 'sum', '_prob')\n",
    "match = pd.concat(match)\n",
    "\n",
    "str_list, idk_strings = fz.build_corpus(train_list[1], 'housing_roof', 'housing_roof_rank', ['1', '2', '3'])\n",
    "distrib = fz.fuzzy_scan(idk_strings, str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define test globals\n",
    "DIGITS = str([str(x) for x in range(100 + 1)])\n",
    "PUNCT = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "SPACE = '     '\n",
    "\n",
    "# if you compile the regex string first, it's even faster\n",
    "re_dig = re.compile('\\d')\n",
    "re_punct = re.compile('\\W+')\n",
    "re_white = re.compile(' +')\n",
    "\n",
    "def test_globals():\n",
    "    \"\"\"This function tests that the test globals are properly defined.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(DIGITS) != None, \"Global doesn't contain digits!\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(PUNCT) != None, \"Global doesn't contain punctuation!\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(SPACE) != None, \"Global doesn't contain whitespace!\"\n",
    "    \n",
    "\n",
    "def test_clean_text():\n",
    "    \"\"\"This function tests that the clean text function is doing its job.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(prep.clean_text(DIGITS)) == None, \"clean_text did not remove the digits from test global.\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(prep.clean_text(PUNCT)) == None, \"clean_text did not remove the punctuation from test global.\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(prep.clean_text(SPACE)) == None, \"clean_text did not remove the whitespace from test global.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
