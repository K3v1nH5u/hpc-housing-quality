{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SANDBOX for code development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#import custom modules\n",
    "import prep.prep_data as prep\n",
    "import prep.prep_cv as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~begin reading\n",
      "data read!\n",
      "~begin cleaning\n",
      "data clean!\n",
      "~applying filter\n"
     ]
    }
   ],
   "source": [
    "df = prep.read_then_clean('../data/housing_data.csv',\n",
    "                          ['housing_roof', 'housing_wall', 'housing_floor'],\n",
    "                          ['MACRO_DHS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nan': nan, 'other': nan, 'not a dejure resident': nan, 'not dejure resident': nan}\n",
      "removing garbage from  housing_roof\n",
      "removing garbage from  housing_wall\n",
      "removing garbage from  housing_floor\n"
     ]
    }
   ],
   "source": [
    "df_clean = prep.remove_garbage_codes(df, \n",
    "                                     ['housing_roof', 'housing_wall', 'housing_floor'],\n",
    "                                     ['nan', 'other', 'not a dejure resident', 'not dejure resident'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_floor</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>4014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alfombra tapete</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alphalt strips</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animal dung</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>argile banco</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asphlat tiles vynil</th>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autre</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autres matriaux moderne</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bamboo</th>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bare wood planks</th>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bois autres vgtaux</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bouse</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brick</th>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brick concrete</th>\n",
       "      <td>6521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brick tiles</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bricks</th>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broken bricks</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cane</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>13046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carpet rug</th>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carrelage</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carrelage ou ciment</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cave tent hut temp r</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cement</th>\n",
       "      <td>116307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cement brick</th>\n",
       "      <td>7643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cement bricks</th>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cement concrete</th>\n",
       "      <td>7046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cement gravel</th>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cement maconery</th>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl linoleum ceramic</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl or alphalt strips</th>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl or arphalt strips</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl or aspalt strips</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl or asphalt</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl or asphalt strips</th>\n",
       "      <td>2641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl or plastic strips</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl pvc or asphalt strips</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl sheets tiles</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl strips asphalt</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyl tile vinyl carpet</th>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyle ou tapis</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vynil or asphalt strips</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall to wall carpet</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weaves palms</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiid planks</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood and tile</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood bats tacos de madeira</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood palm bamboo</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood plank</th>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood planks</th>\n",
       "      <td>21645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood planks bamboo plam</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood planks boards</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood planks palm bamboo</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood polished</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood tambo</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wooden tile</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woolen carpets synthetic carpet</th>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woolen carpets synthetic carpets</th>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0                              count\n",
       "housing_floor                           \n",
       "                                    4014\n",
       "adobe                                623\n",
       "alfombra tapete                        2\n",
       "alphalt strips                       131\n",
       "animal dung                           29\n",
       "argile banco                           3\n",
       "asphlat tiles vynil                  790\n",
       "autre                                 11\n",
       "autres matriaux moderne                2\n",
       "bamboo                              1033\n",
       "bare wood planks                     735\n",
       "bois autres vgtaux                    51\n",
       "bouse                                 18\n",
       "brick                                313\n",
       "brick concrete                      6521\n",
       "brick tiles                          101\n",
       "bricks                              1554\n",
       "broken bricks                         52\n",
       "cane                                  15\n",
       "carpet                             13046\n",
       "carpet rug                          1098\n",
       "carrelage                             89\n",
       "carrelage ou ciment                   14\n",
       "cave tent hut temp r                  28\n",
       "cement                            116307\n",
       "cement brick                        7643\n",
       "cement bricks                        626\n",
       "cement concrete                     7046\n",
       "cement gravel                        607\n",
       "cement maconery                      297\n",
       "...                                  ...\n",
       "vinyl linoleum ceramic               130\n",
       "vinyl or alphalt strips              216\n",
       "vinyl or arphalt strips               37\n",
       "vinyl or aspalt strips               116\n",
       "vinyl or asphalt                      24\n",
       "vinyl or asphalt strips             2641\n",
       "vinyl or plastic strips              241\n",
       "vinyl pvc or asphalt strips           14\n",
       "vinyl sheets tiles                   111\n",
       "vinyl strips asphalt                 116\n",
       "vinyl tile vinyl carpet              900\n",
       "vinyle ou tapis                       24\n",
       "vynil or asphalt strips               13\n",
       "wall to wall carpet                  672\n",
       "weaves palms                          18\n",
       "wiid planks                           11\n",
       "wood                                6750\n",
       "wood and tile                         21\n",
       "wood bats tacos de madeira            49\n",
       "wood palm bamboo                       5\n",
       "wood plank                           591\n",
       "wood planks                        21645\n",
       "wood planks bamboo plam                5\n",
       "wood planks boards                     4\n",
       "wood planks palm bamboo               25\n",
       "wood polished                         21\n",
       "wood tambo                           104\n",
       "wooden tile                            6\n",
       "woolen carpets synthetic carpet      463\n",
       "woolen carpets synthetic carpets     388\n",
       "\n",
       "[262 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_clean['housing_floor'], columns='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_list = cv.cv_censor_col(df, 'housing_roof_num', .2, 'N', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./prep/prep_cv.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./prep/prep_cv.py\n",
    "\n",
    "#define necessary helper functions\n",
    "def cv_censor_col(df, colname, pct=.2, weight_var=None, reps=5):\n",
    "    \n",
    "    \"\"\"This function is used to create pandas dfs where a specified % of the values in a column have been censored\n",
    "    and replaced with NaN, so that they can be predicted in a cross-validation methodology. It returns a list of such\n",
    "    dfs that is the length of the reps argument.\n",
    "\n",
    "    Args:\n",
    "        df (pandas df): This is a pandas df that has columns with garbage values to be removed.\n",
    "        colname (str): This is a string indicating the name of a column that you want to censor and later predict.\n",
    "        pct (float): This is a value between 0-1 that indicates the fraction of values you want to censor. Default = 20%\n",
    "        weight_var (str): This is a string indicating the column name is used to weighted the sample. Default = No weight.\n",
    "        reps (int): This is an integer indicating the number of different training datasets to create. Default = 5x\n",
    "\n",
    "    Returns:\n",
    "        df_clean: This function returns a pandas df where the garbage codes have been replaced with NaN.\n",
    "        \n",
    "    TODO: ?\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #import packages\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    for x in range(reps):\n",
    "            \n",
    "        print(\"sampling df, iteration #\", x)\n",
    "    \n",
    "        #first archive your old column in order to test later\n",
    "        new_df = df.copy()\n",
    "        new_df[colname + '_og'] = new_df[colname]\n",
    "\n",
    "        #draw a weighted sample if weight var is specified\n",
    "        if weight_var != None:\n",
    "            df_censor = new_df.sample(frac=pct, weights=weight_var)\n",
    "        else:\n",
    "            df_censor = new_df.sample(frac=pct)\n",
    "            \n",
    "        #now replace the sampled column with missing values in order to try and predict\n",
    "        #note that replacement is only done on the sampled indices\n",
    "        df_censor[colname] = \"replace_me\"\n",
    "        new_df.update(df_censor, overwrite=True)\n",
    "        new_df[colname].replace(\"replace_me\", np.nan, inplace=True)\n",
    "        #TODO unsure if this is pythonic method but it seems like df.update won't replace values with NaN, \n",
    "        #as such, need to do this workaround\n",
    "        \n",
    "        #store the result (df with columns censored)\n",
    "        out.append(new_df)\n",
    "    \n",
    "    #return the list of sampled dfs\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#look at output datset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.housing_roof.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define test globals\n",
    "DIGITS = str([str(x) for x in range(100 + 1)])\n",
    "PUNCT = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "SPACE = '     '\n",
    "\n",
    "# if you compile the regex string first, it's even faster\n",
    "re_dig = re.compile('\\d')\n",
    "re_punct = re.compile('\\W+')\n",
    "re_white = re.compile(' +')\n",
    "\n",
    "def test_globals():\n",
    "    \"\"\"This function tests that the test globals are properly defined.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(DIGITS) != None, \"Global doesn't contain digits!\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(PUNCT) != None, \"Global doesn't contain punctuation!\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(SPACE) != None, \"Global doesn't contain whitespace!\"\n",
    "    \n",
    "\n",
    "def test_clean_text():\n",
    "    \"\"\"This function tests that the clean text function is doing its job.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(prep.clean_text(DIGITS)) == None, \"clean_text did not remove the digits from test global.\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(prep.clean_text(PUNCT)) == None, \"clean_text did not remove the punctuation from test global.\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(prep.clean_text(SPACE)) == None, \"clean_text did not remove the whitespace from test global.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./tests/test_prep.py\n",
    "#write tests\n",
    "\"\"\"This is a module used to test a module: \"prep.py\" and its relevant functions read_then_clean and clean_text\n",
    "\n",
    "read_then_clean is a function that takes a csv with messy string values and \n",
    "creates then cleans a pandas df\n",
    "using clean_text\n",
    "\n",
    "This module tests that function by ensuring that it returns expected exceptions and\n",
    "does not contain unexpected values.\n",
    "\"\"\"\n",
    "# import packages\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#import custom modules fpr testing\n",
    "import prep.prep_data as prep\n",
    "\n",
    "#set globals for tests\n",
    "FILEPATH = '../data/housing_data.csv'\n",
    "CLEAN_COLS = ['housing_roof', 'housing_wall', 'housing_floor']\n",
    "DIGITS = str([str(x) for x in range(100 + 1)])\n",
    "PUNCT = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "SPACE = '     '\n",
    "\n",
    "# if you compile the regex string first, it's even faster\n",
    "re_dig = re.compile('\\d')\n",
    "re_punct = re.compile('\\W+')\n",
    "re_white = re.compile(' +')\n",
    "\n",
    "def test_globals():\n",
    "    \"\"\"This function tests that the test globals are properly defined.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(DIGITS) != None, \"global doesn't contain digits!\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(PUNCT) != None, \"global doesn't contain punctuation!\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(SPACE) != None, \"global doesn't contain whitespace!\"\n",
    "    \n",
    "\n",
    "def test_clean_text():\n",
    "    \"\"\"This function tests that the clean text function is doing its job.\n",
    "    \"\"\"\n",
    "    #assert that digits are removed\n",
    "    assert re_dig.search(prep.clean_text(DIGITS)) == None, \"clean_text did not remove the digits from test global.\" \n",
    "    #assert that punctutation is removed\n",
    "    assert re_punct.search(prep.clean_text(PUNCT)) == None, \"clean_text did not remove the punctuation from test global.\"\n",
    "    #assert that excessive whitespace is removed\n",
    "    assert re_white.search(prep.clean_text(SPACE)) == None, \"clean_text did not remove the whitespace from test global.\"\n",
    "\n",
    "# This is our base dataset and it needs to be cleaned properly. The second argument specifies\n",
    "# the cols with string values that we want to be cleaned.\n",
    "\n",
    "\n",
    "#TODO, how to cause read_then_clean to raise the row count exception??\n",
    "def test_read_then_clean():\n",
    "    \"\"\"This function tests that a custom exception called RowCountException\n",
    "    will be returned when more than 1k rows are expected.\n",
    "    \"\"\"\n",
    "    with pytest.raises(Exception) as err:\n",
    "        test_df = prep.read_then_clean(FILEPATH,\n",
    "                                       CLEAN_COLS)\n",
    "    assert 'RowCountException' in str(err) #verify that your custom error is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./prep/prep_data.py\n",
    "#define necessary helper functions\n",
    "def clean_text(text):\n",
    "    \"\"\"This function is used to clean a selection of text. \n",
    "    It uses several regular expressions and built in text commands in order to remove commonly seen \n",
    "    errors,\n",
    "    nonsense values, \n",
    "    punctuation, \n",
    "    digits, and \n",
    "    extra whitespace.\n",
    "\n",
    "    Args:\n",
    "        text (str): This is a text value that needs to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        text: This function returns a cleaned version of the input text.\n",
    "        \n",
    "    TODO: Add functionality to impute a selected value for NaN or missing values?\n",
    "\n",
    "    \"\"\"\n",
    "    #import necessary modules\n",
    "    import re\n",
    "    \n",
    "    #force all vals in series to string\n",
    "    text = str(text)\n",
    "    \n",
    "    #first remove uppercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove common errors\n",
    "    text = re.sub(r\"\\[.]\", \"\", text) \n",
    "    text = re.sub(r\"\\<ff>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<fb>\", \"\", text)\n",
    "    text = re.sub(r\"\\<a\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<c\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<d\\d>\", \"\", text)\n",
    "    text = re.sub(r\"\\<e\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\<f\\d>\", \"\", text)   \n",
    "    text = re.sub(r\"\\d+\\.\", \"\", text)\n",
    "\n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)   \n",
    "\n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    \n",
    "    # remove any remaining digit codes\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    \n",
    "    # remove any leading/trailing/duplicate whitespace\n",
    "    text = re.sub(' +', ' ', text.strip())\n",
    "    \n",
    "    return text\n",
    "    \n",
    "#define master function\n",
    "def read_then_clean(file_path, vars_to_clean, filter_series=None):\n",
    "    \"\"\"This is the master function for this module. It uses the previously defined helper functions,\n",
    "    in order to output a clean dataset for user. It reads in a selected .csv file from a given filepath,\n",
    "    and applies the previously defined cleaning functions to a list of variables provided by user.\n",
    "    \n",
    "    It can also optionally filter the df based on the survey series or TODO language.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): This is a string indicating which file that you want to read in.\n",
    "        vars_to_clean (list): This is a list of strings that indicate which columns you want to clean.\n",
    "        filter_series (list): This is a list of strings that indicate which survey series to keep.\n",
    "\n",
    "    Returns:\n",
    "        df_clean: This is a pandas df that has columns of text values that have been cleaned using the helper function.\n",
    "        \n",
    "    TODO: Is it better to return an obj called df_clean to be more explicit to user?\n",
    "\n",
    "    \"\"\"\n",
    "    #import necessary modules\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    #read in your data\n",
    "    print(\"~begin reading\")\n",
    "    df_raw = pd.read_csv(file_path, low_memory=False)\n",
    "    min_nrow = len(df_raw) #save the row count to test after cleaning and verify that rows are not being dropped\n",
    "    print(\"data read!\")\n",
    "    \n",
    "    #cleanup\n",
    "    print(\"~begin cleaning\")\n",
    "    df_clean = df_raw.copy()\n",
    "    for var in vars_to_clean:\n",
    "        df_clean[var] = df_clean[var].apply(clean_text)\n",
    "    print(\"data clean!\")\n",
    "    \n",
    "    # Verify that the minimum rowcount continues to be met\n",
    "    if len(df_clean) < min_nrow:\n",
    "        class RowCountException(Exception):\n",
    "            \"\"\"Custom exception class.\n",
    "            \n",
    "            This exception is raised when the minimum row is unmet.\n",
    "\n",
    "            \"\"\"\n",
    "            pass\n",
    "        \n",
    "        raise RowCountException(\"Minimum number of rows were not returned after cleaning. Data is being lost!\")\n",
    "        \n",
    "    # Filter data if filter arguments are provided by user\n",
    "    if filter_series != None:\n",
    "        print(\"~applying filter\")\n",
    "        df_clean = df_clean[df_clean['survey_series'].isin(filter_series)]\n",
    "        \n",
    "    #output a clean dataset\n",
    "    return df_clean\n",
    "\n",
    "#define function to replace meaningless values with NaNs\n",
    "def remove_garbage_codes(df, vars_to_clean, garbage_list):\n",
    "    \"\"\"This function is used to remove garbage values from a pandas df, replacing them with NaN.\n",
    "\n",
    "    Args:\n",
    "    df (pandas df): This is a pandas df that has columns with garbage values to be removed.\n",
    "    vars_to_clean (list): This is a list of strings that indicate which columns you want to clean.\n",
    "    garbage_list (list): This is a list of strings that indicate which garbage values to replace with NaN\n",
    "\n",
    "    Returns:\n",
    "        df_clean: This function returns a pandas df where the garbage codes have been replaced with NaN.\n",
    "        \n",
    "    TODO: ?\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #import necessary modules\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # build dictionary to map all garbage values to NaN\n",
    "    garb_dict = {}\n",
    "    for string in garbage_list:\n",
    "        garb_dict[string] = np.nan\n",
    "    \n",
    "    print(garb_dict)\n",
    "    \n",
    "    for var in vars_to_clean:\n",
    "        print(\"removing garbage from \", var)\n",
    "        #df_clean[var] = df_clean[var].map(garb_dict).fillna(df_clean[var]) \n",
    "        #necessary to add fillna because map is non-exhaustive\n",
    "        df_clean[var].replace(garb_dict, inplace=True)\n",
    "        \n",
    "    #output a clean dataset\n",
    "    return df_clean    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraps\n",
    "DIGITS = str([str(x) for x in range(100 + 1)])\n",
    "PUNCT = \"xx\"\n",
    "#PUNCT = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "SPACE = '     '\n",
    "\n",
    "(DIGITS)\n",
    "test_globals()\n",
    "#look at some of the clean values\n",
    "df_raw.housing_floor.unique().tolist()\n",
    "clean_text('32. vinyl_asphalt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
